{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    image_extensions = ['.jpg']\n",
    "    image_names = []\n",
    "    for filename in os.listdir(path):\n",
    "        if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "            image_names.append(filename)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ayanfe/Documents/Datasets/animefaces256cleaner'\n",
    "path1 = '/Users/ayanfe/Documents/Code/Diffusion Model/model/model.pth'\n",
    "model_two = '/Users/ayanfe/Documents/Code/Diffusion Model/model/model_fixed_10000.pth'\n",
    "image_names = get_data(path)\n",
    "print(len(image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 200\n",
    "\n",
    "# create a fixed beta schedule\n",
    "beta = np.linspace(0.0001, 0.02, timesteps)\n",
    "\n",
    "# this will be used as discussed in the reparameterization trick\n",
    "alpha = 1 - beta\n",
    "alpha_bar = np.cumprod(alpha, 0)\n",
    "alpha_bar = np.concatenate((np.array([1.]), alpha_bar[:-1]), axis=0)\n",
    "sqrt_alpha_bar = np.sqrt(alpha_bar)\n",
    "one_minus_sqrt_alpha_bar = np.sqrt(1-alpha_bar)\n",
    "\n",
    "# this function will help us set the RNG key for Numpy\n",
    "def set_key(key):\n",
    "    np.random.seed(key)\n",
    "\n",
    "# this function will add noise to the input as per the given timestamp\n",
    "def forward_noise(key, x_0, t):\n",
    "    set_key(key)\n",
    "    noise = np.random.normal(size=x_0.shape)\n",
    "    reshaped_sqrt_alpha_bar_t = np.reshape(np.take(sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    reshaped_one_minus_sqrt_alpha_bar_t = np.reshape(np.take(one_minus_sqrt_alpha_bar, t), (-1, 1, 1, 1))\n",
    "    noisy_image = reshaped_sqrt_alpha_bar_t  * x_0/255 + reshaped_one_minus_sqrt_alpha_bar_t  * noise\n",
    "    return noisy_image, noise\n",
    "\n",
    "# this function will be used to create sample timestamps between 0 & T\n",
    "def generate_timestamp(key, num):\n",
    "    set_key(key)\n",
    "    return torch.randint(0, timesteps,(num,), dtype=torch.int32)\n",
    "\n",
    "def reshape_img(img,size = (64,64)):\n",
    "    data = cv2.resize(img,size)\n",
    "    data = np.transpose(data,(2,0,1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the output image at some timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us visualize the output image at a few timestamps\n",
    "sample_data = plt.imread(path+'/'+image_names[0])\n",
    "\n",
    "for index, i in enumerate([0,10, 100, 150, 199]):\n",
    "    noisy_im, noise = forward_noise(0, np.expand_dims(sample_data, 0), np.array([i,]))\n",
    "    plt.subplot(1, 5, index+1)\n",
    "    plt.imshow(np.squeeze(noisy_im,0))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddim(x_t, pred_noise, t, sigma_t):\n",
    "    #alpha_t_bar = np.take(alpha_bar, t)\n",
    "    #alpha_t_minus_one = np.take(alpha, t-1)\n",
    "    alpha_t_bar = np.take(alpha_bar, t.astype(int))  # Cast t to integer before using np.take\n",
    "    alpha_t_minus_one = np.take(alpha, (t - 1).astype(int))  # Similarly, cast t-1 to integer\n",
    "\n",
    "    #alpha_t_bar = torch.from_numpy(alpha_t_bar)\n",
    "    #alpha_t_minus_one = torch.from_numpy(alpha_t_minus_one)\n",
    "\n",
    "    pred = (x_t - ((1 - alpha_t_bar) ** 0.5) * pred_noise)/ (alpha_t_bar ** 0.5)\n",
    "    pred = (alpha_t_minus_one ** 0.5) * pred\n",
    "\n",
    "    pred = pred + ((1 - alpha_t_minus_one - (sigma_t ** 2)) ** 0.5) * pred_noise\n",
    "    eps_t = np.random.normal(size=x_t.shape)\n",
    "    pred = pred+(sigma_t * eps_t)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, device, num_samples=5):\n",
    "    # Define number of inference loops to run\n",
    "    inference_timesteps = 10\n",
    "    \n",
    "    # Create a range of inference steps that the output should be sampled at\n",
    "    inference_range = range(0, timesteps, timesteps // inference_timesteps)\n",
    "    \n",
    "    x = torch.randn(1, 3, 64, 64).to(device)  # Initialize a random input image on GPU\n",
    "    img_list = []\n",
    "    img_list.append(np.squeeze(x.cpu().numpy(), 0))  # Append the initial image\n",
    "    \n",
    "    # Iterate over inference_timesteps\n",
    "    for i in range(inference_timesteps):\n",
    "        t = np.expand_dims(inference_range[i], 0)\n",
    "        t = torch.from_numpy(t).type(torch.float32).to(device)\n",
    "        t = torch.reshape(t, (-1, 1)).type(torch.float32)\n",
    "        print(t.shape)\n",
    "        \n",
    "        pred_noise = model(x, t).detach().to(device)  # Obtain predicted noise\n",
    "        \n",
    "        x = ddim(x.cpu().detach().numpy(), pred_noise.cpu().detach().numpy(), t.cpu().detach().numpy(), 0)  # Perform denoising using DDIM\n",
    "        x = torch.from_numpy(x).type(torch.float32).to(device)  # Transfer denoised image back to GPU\n",
    "        img_list.append(np.squeeze(x.cpu().detach().numpy(), 0))  # Append the denoised image\n",
    "    \n",
    "    # Visualize the final denoised image\n",
    "    plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = 60001\n",
    "\n",
    "start = 1\n",
    "img_length = len(image_names)\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, device, accumulation_steps=1, epoch_start = 0, batch_size = 32):\n",
    "    global start\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        for epoch in range(epoch_start, n_epochs + 1):\n",
    "            loss_train = 0.0\n",
    "            accumulated_loss = 0.0\n",
    "            loss_mae = 0.0\n",
    "            \n",
    "            # Use tqdm function for the progress bar\n",
    "            with tqdm(range(start, 10001), desc=f'Epoch {epoch}', unit=' images') as pbar:\n",
    "                for x in pbar:\n",
    "                    # Training loop code\n",
    "                    img_arr = []\n",
    "                    random_imgs = random.sample(range(0, timesteps), batch_size)\n",
    "                    for i in random_imgs:\n",
    "                        img = plt.imread(path + '/' + image_names[i])\n",
    "                        img = reshape_img(img)\n",
    "                        img = np.expand_dims(img, 0)\n",
    "                        img_arr.append(img)\n",
    "                    \n",
    "                    t = generate_timestamp(0, timesteps)\n",
    "                    t = torch.reshape(t, (-1, 1)).type(torch.float32)\n",
    "                    \n",
    "                    imgs, noise = forward_noise(0, img_arr, t)\n",
    "                    \n",
    "                    imgs = torch.from_numpy(imgs).type(torch.float32).to(device)\n",
    "                    noise = torch.from_numpy(noise).type(torch.float32).to(device)\n",
    "                    t = t.to(device)\n",
    "                   \n",
    "                    outputs = model(imgs, t)\n",
    "                    \n",
    "                    loss = loss_fn(outputs, noise)\n",
    "                    \n",
    "                    # Perform gradient accumulation\n",
    "                    accumulated_loss += loss / accumulation_steps\n",
    "                    \n",
    "                    if x % accumulation_steps == 0:\n",
    "                        accumulated_loss.backward()\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        accumulated_loss = 0.0  # Reset accumulated loss\n",
    "                    \n",
    "                    loss_train += loss.item()\n",
    "                    outputs.detach_()\n",
    "                    pbar.set_postfix(loss=loss.item())\n",
    "                \n",
    "            avg_loss_epoch = loss_train / len(image_names)\n",
    "            with open(\"model_fixed_1000_loss.txt\", \"a\") as file:\n",
    "                file.write(f\"Epoch {epoch}: Average Loss: {avg_loss_epoch}\\n\")\n",
    "            \n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(image_names)))\n",
    "            inference(model, device)\n",
    "            #torch.save(model.state_dict(), path1)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, model_two)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import Unet\n",
    "\n",
    "model = Unet()\n",
    "#model.load_state_dict(torch.load(model_two))\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0005)  #  <3>\n",
    "#checkpoint = torch.load(model_two)\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total parameters: \",count_parameters(model))\n",
    "loss_fn = nn.MSELoss()  #  <4>\n",
    "\n",
    "training_loop(  # <5>\n",
    "    n_epochs = 50,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    device = device,\n",
    "    epoch_start = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = torch.rand(10,3,128,128).numpy()\n",
    "t = torch.range(1,10)\n",
    "print(t.shape)\n",
    "sg, ns = forward_noise(0,x_0,t)\n",
    "print(sg.shape)\n",
    "print(ns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
